{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LSTM\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaDiscriminator:\n",
    "    def __init__(self, max_sequence_len):\n",
    "        self.max_sequence_len = max_sequence_len\n",
    "    \n",
    "    def build_model(self):\n",
    "        txt_shape = (self.max_sequence_len, 1, 1)\n",
    "        model = Sequential(name='VanillaDiscriminator')\n",
    "        model.add(Flatten(input_shape=txt_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "        txt = Input(shape=txt_shape)\n",
    "        validity = model(txt)\n",
    "        self.discriminator = Model(txt, validity)\n",
    "        return self.discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaGenerator:\n",
    "    def __init__(self, max_sequence_len):\n",
    "        self.max_sequence_len = max_sequence_len\n",
    "    \n",
    "    def build_model(self):\n",
    "        noise_shape = (self.max_sequence_len, 1)\n",
    "        model = Sequential(name='VanillaGenerator')\n",
    "        model.add(LSTM(256, input_shape=noise_shape))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(noise_shape[0], activation='tanh'))\n",
    "        model.summary()\n",
    "        noise = Input(shape=noise_shape)\n",
    "        txt = model(noise)\n",
    "        self.generator = Model(noise, txt)\n",
    "        return self.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGAN:\n",
    "    def __init__(self, discriminator, generator, max_sequence_len):\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.max_sequence_len = max_sequence_len\n",
    "        \n",
    "    def build_model(self):\n",
    "        self.discriminator.trainable = False # it's important to freeze the discriminator when training the generator\n",
    "        gan_input = Input(shape=(self.max_sequence_len, 1)) # The GAN takes noise as input \n",
    "        generator_out = self.generator(gan_input) # generates text output\n",
    "        gan_output = self.discriminator(generator_out) # and validates generated text \n",
    "        self.gan =  Model(gan_input, gan_output, name='GAN')\n",
    "        self.gan.summary()\n",
    "        return self.gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANTrainer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, X_train, discriminator, generator, gan, batch_size, epochs):\n",
    "        half_batch = int(batch_size/2)\n",
    "        for epoch in range(epochs):\n",
    "            ##########################\n",
    "            # train the discriminator on half-real and half-fake data\n",
    "            ##########################\n",
    "            # get random half-batch real data\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            txts = X_train[idx]\n",
    "\n",
    "            # get half-batch fake data\n",
    "            noise = np.random.normal(-10, 10, (half_batch, columns, 1))\n",
    "            gen_txts = generator.predict(noise)\n",
    "            gen_txts = np.expand_dims(gen_txts, axis=2)\n",
    "            gen_txts = np.expand_dims(gen_txts, axis=3)\n",
    "\n",
    "            # compute discriminator losses on real and fake data and average them\n",
    "            d_loss_real = discriminator.train_on_batch(txts, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_txts, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            ##########################\n",
    "            # train the GAN, thereby traning the generator (on full-batch data)\n",
    "            # the discriminator is not trained in the GAN because it's trainable flag is set to False \n",
    "            ##########################\n",
    "            noise = np.random.normal(0, 1, (batch_size, columns, 1))\n",
    "            # the generator wants discriminator to mistake texts as real. Therefore send np.ones as labels\n",
    "            g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11667 768 1\n",
      "(11667, 768, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# data loading and preprocessing\n",
    "data = pickle.load(open(\"X.p\",\"rb\"))\n",
    "X_train = data\n",
    "rows, columns, channels = X_train.shape\n",
    "print(rows, columns, channels)\n",
    "# expand the last dimension\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8.960256e+06\n",
       "mean    -9.478921e-03\n",
       "std      5.208932e-01\n",
       "min     -9.697466e+00\n",
       "25%     -2.290757e-01\n",
       "50%      1.008263e-02\n",
       "75%      2.507721e-01\n",
       "max      5.218259e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(data.reshape(-1)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter initializations\n",
    "max_sequence_len = columns\n",
    "batch_size = 1024\n",
    "epochs = 100\n",
    "optimizer = Adam(0.0002, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VanillaDiscriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               393728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 525,313\n",
      "Trainable params: 525,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = VanillaDiscriminator(max_sequence_len).build_model()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VanillaGenerator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 768)               197376    \n",
      "=================================================================\n",
      "Total params: 461,568\n",
      "Trainable params: 461,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = VanillaGenerator(max_sequence_len).build_model()\n",
    "generator.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GAN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 768, 1)]          0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 768)               461568    \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 1)                 525313    \n",
      "=================================================================\n",
      "Total params: 986,881\n",
      "Trainable params: 461,568\n",
      "Non-trainable params: 525,313\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = TextGAN(discriminator, generator, max_sequence_len).build_model()\n",
    "gan.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.617149, acc.: 90.82%] [G loss: 0.693364]\n",
      "1 [D loss: 0.435834, acc.: 98.83%] [G loss: 0.686573]\n",
      "2 [D loss: 0.315553, acc.: 99.51%] [G loss: 0.681070]\n",
      "3 [D loss: 0.263909, acc.: 99.41%] [G loss: 0.671529]\n",
      "4 [D loss: 0.206514, acc.: 99.71%] [G loss: 0.663338]\n",
      "5 [D loss: 0.166372, acc.: 99.71%] [G loss: 0.645630]\n",
      "6 [D loss: 0.127427, acc.: 99.71%] [G loss: 0.618740]\n",
      "7 [D loss: 0.088723, acc.: 99.80%] [G loss: 0.550577]\n",
      "8 [D loss: 0.054997, acc.: 99.90%] [G loss: 0.140953]\n",
      "9 [D loss: 0.034194, acc.: 99.80%] [G loss: 0.003710]\n",
      "10 [D loss: 0.028065, acc.: 99.80%] [G loss: 0.005713]\n",
      "11 [D loss: 0.026987, acc.: 99.90%] [G loss: 0.000938]\n",
      "12 [D loss: 0.021318, acc.: 99.80%] [G loss: 0.000011]\n",
      "13 [D loss: 0.019714, acc.: 99.90%] [G loss: 0.001052]\n",
      "14 [D loss: 0.016533, acc.: 99.80%] [G loss: 0.000008]\n",
      "15 [D loss: 0.015007, acc.: 99.90%] [G loss: 0.001152]\n",
      "16 [D loss: 0.016457, acc.: 99.71%] [G loss: 0.000006]\n",
      "17 [D loss: 0.017857, acc.: 99.90%] [G loss: 0.000006]\n",
      "18 [D loss: 0.017108, acc.: 99.80%] [G loss: 0.000006]\n",
      "19 [D loss: 0.008539, acc.: 100.00%] [G loss: 0.000005]\n",
      "20 [D loss: 0.010250, acc.: 99.90%] [G loss: 0.000005]\n",
      "21 [D loss: 0.011848, acc.: 99.71%] [G loss: 0.000004]\n",
      "22 [D loss: 0.007731, acc.: 99.90%] [G loss: 0.000004]\n",
      "23 [D loss: 0.008064, acc.: 99.90%] [G loss: 0.000004]\n",
      "24 [D loss: 0.011465, acc.: 99.71%] [G loss: 0.000003]\n",
      "25 [D loss: 0.008000, acc.: 99.90%] [G loss: 0.000003]\n",
      "26 [D loss: 0.007397, acc.: 99.90%] [G loss: 0.000003]\n",
      "27 [D loss: 0.005691, acc.: 99.90%] [G loss: 0.000003]\n",
      "28 [D loss: 0.008219, acc.: 99.80%] [G loss: 0.000003]\n",
      "29 [D loss: 0.005290, acc.: 100.00%] [G loss: 0.000002]\n",
      "30 [D loss: 0.004370, acc.: 99.90%] [G loss: 0.000002]\n",
      "31 [D loss: 0.006231, acc.: 99.90%] [G loss: 0.000002]\n",
      "32 [D loss: 0.003977, acc.: 100.00%] [G loss: 0.000002]\n",
      "33 [D loss: 0.005143, acc.: 99.90%] [G loss: 0.000002]\n",
      "34 [D loss: 0.007226, acc.: 99.80%] [G loss: 0.000002]\n",
      "35 [D loss: 0.006199, acc.: 99.80%] [G loss: 0.000002]\n",
      "36 [D loss: 0.002974, acc.: 100.00%] [G loss: 0.000002]\n",
      "37 [D loss: 0.003465, acc.: 100.00%] [G loss: 0.000001]\n",
      "38 [D loss: 0.004169, acc.: 99.90%] [G loss: 0.000001]\n",
      "39 [D loss: 0.002802, acc.: 100.00%] [G loss: 0.000001]\n",
      "40 [D loss: 0.004407, acc.: 99.80%] [G loss: 0.000001]\n",
      "41 [D loss: 0.007014, acc.: 99.80%] [G loss: 0.000001]\n",
      "42 [D loss: 0.003469, acc.: 100.00%] [G loss: 0.000001]\n",
      "43 [D loss: 0.007896, acc.: 99.80%] [G loss: 0.000001]\n",
      "44 [D loss: 0.003162, acc.: 100.00%] [G loss: 0.000001]\n",
      "45 [D loss: 0.002288, acc.: 100.00%] [G loss: 0.000001]\n",
      "46 [D loss: 0.003516, acc.: 99.90%] [G loss: 0.000001]\n",
      "47 [D loss: 0.003261, acc.: 99.90%] [G loss: 0.000001]\n",
      "48 [D loss: 0.002009, acc.: 100.00%] [G loss: 0.000001]\n",
      "49 [D loss: 0.004524, acc.: 99.80%] [G loss: 0.000001]\n",
      "50 [D loss: 0.002454, acc.: 100.00%] [G loss: 0.000001]\n",
      "51 [D loss: 0.003296, acc.: 100.00%] [G loss: 0.000001]\n",
      "52 [D loss: 0.001881, acc.: 100.00%] [G loss: 0.000001]\n",
      "53 [D loss: 0.002060, acc.: 100.00%] [G loss: 0.000001]\n",
      "54 [D loss: 0.001962, acc.: 100.00%] [G loss: 0.000001]\n",
      "55 [D loss: 0.001705, acc.: 100.00%] [G loss: 0.000001]\n",
      "56 [D loss: 0.001343, acc.: 100.00%] [G loss: 0.000001]\n",
      "57 [D loss: 0.001523, acc.: 100.00%] [G loss: 0.000001]\n",
      "58 [D loss: 0.002247, acc.: 100.00%] [G loss: 0.000001]\n",
      "59 [D loss: 0.004612, acc.: 99.90%] [G loss: 0.000001]\n",
      "60 [D loss: 0.004400, acc.: 99.90%] [G loss: 0.000001]\n",
      "61 [D loss: 0.001304, acc.: 100.00%] [G loss: 0.000001]\n",
      "62 [D loss: 0.002715, acc.: 99.90%] [G loss: 0.000001]\n",
      "63 [D loss: 0.001532, acc.: 100.00%] [G loss: 0.000001]\n",
      "64 [D loss: 0.001471, acc.: 100.00%] [G loss: 0.000001]\n",
      "65 [D loss: 0.004104, acc.: 99.80%] [G loss: 0.000001]\n",
      "66 [D loss: 0.000976, acc.: 100.00%] [G loss: 0.000001]\n",
      "67 [D loss: 0.001033, acc.: 100.00%] [G loss: 0.000001]\n",
      "68 [D loss: 0.003116, acc.: 99.90%] [G loss: 0.000001]\n",
      "69 [D loss: 0.002859, acc.: 99.90%] [G loss: 0.000001]\n",
      "70 [D loss: 0.002288, acc.: 100.00%] [G loss: 0.000001]\n",
      "71 [D loss: 0.004124, acc.: 99.80%] [G loss: 0.000001]\n",
      "72 [D loss: 0.002157, acc.: 99.90%] [G loss: 0.000001]\n",
      "73 [D loss: 0.002013, acc.: 100.00%] [G loss: 0.000001]\n",
      "74 [D loss: 0.000759, acc.: 100.00%] [G loss: 0.000001]\n",
      "75 [D loss: 0.000594, acc.: 100.00%] [G loss: 0.000001]\n",
      "76 [D loss: 0.000825, acc.: 100.00%] [G loss: 0.000001]\n",
      "77 [D loss: 0.000943, acc.: 100.00%] [G loss: 0.000000]\n",
      "78 [D loss: 0.002969, acc.: 99.90%] [G loss: 0.000000]\n",
      "79 [D loss: 0.000822, acc.: 100.00%] [G loss: 0.000000]\n",
      "80 [D loss: 0.002072, acc.: 99.90%] [G loss: 0.000000]\n",
      "81 [D loss: 0.002180, acc.: 99.90%] [G loss: 0.000001]\n",
      "82 [D loss: 0.000871, acc.: 100.00%] [G loss: 0.000000]\n",
      "83 [D loss: 0.001957, acc.: 99.90%] [G loss: 0.000000]\n",
      "84 [D loss: 0.001534, acc.: 100.00%] [G loss: 0.000000]\n",
      "85 [D loss: 0.001279, acc.: 100.00%] [G loss: 0.000000]\n",
      "86 [D loss: 0.002705, acc.: 99.90%] [G loss: 0.000000]\n",
      "87 [D loss: 0.001118, acc.: 100.00%] [G loss: 0.000000]\n",
      "88 [D loss: 0.001726, acc.: 99.90%] [G loss: 0.000000]\n",
      "89 [D loss: 0.001953, acc.: 100.00%] [G loss: 0.000000]\n",
      "90 [D loss: 0.000394, acc.: 100.00%] [G loss: 0.000000]\n",
      "91 [D loss: 0.001971, acc.: 99.90%] [G loss: 0.000000]\n",
      "92 [D loss: 0.002279, acc.: 99.90%] [G loss: 0.000000]\n",
      "93 [D loss: 0.001543, acc.: 99.90%] [G loss: 0.000000]\n",
      "94 [D loss: 0.000561, acc.: 100.00%] [G loss: 0.000000]\n",
      "95 [D loss: 0.000419, acc.: 100.00%] [G loss: 0.000000]\n",
      "96 [D loss: 0.001017, acc.: 100.00%] [G loss: 0.000000]\n",
      "97 [D loss: 0.000811, acc.: 100.00%] [G loss: 0.000000]\n",
      "98 [D loss: 0.001260, acc.: 100.00%] [G loss: 0.000000]\n",
      "99 [D loss: 0.000973, acc.: 100.00%] [G loss: 0.000000]\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "GANTrainer().train(X_train, discriminator, generator, gan, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58499175],\n",
       "       [0.5200966 ],\n",
       "       [0.50010216],\n",
       "       ...,\n",
       "       [0.5227137 ],\n",
       "       [0.5246207 ],\n",
       "       [0.37355912]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gridsan/SW26425/.conda/envs/vanillagan/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: discrinimator_model/assets\n"
     ]
    }
   ],
   "source": [
    "discriminator.save('discrinimator_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = tf.keras.models.load_model('discrinimator_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14014 768 1\n",
      "(14014, 768, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# data loading and preprocessing\n",
    "data_test = pickle.load(open(\"X_test.p\",\"rb\"))\n",
    "X_test = data_test\n",
    "rows, columns, channels = X_test.shape\n",
    "print(rows, columns, channels)\n",
    "# expand the last dimension\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14009</th>\n",
       "      <td>0.999681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14010</th>\n",
       "      <td>0.999841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14011</th>\n",
       "      <td>0.999943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14012</th>\n",
       "      <td>0.999892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14013</th>\n",
       "      <td>0.999813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14014 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0      0.999412\n",
       "1      0.999844\n",
       "2      0.999943\n",
       "3      0.999900\n",
       "4      0.999872\n",
       "...         ...\n",
       "14009  0.999681\n",
       "14010  0.999841\n",
       "14011  0.999943\n",
       "14012  0.999892\n",
       "14013  0.999813\n",
       "\n",
       "[14014 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pred_df = pd.DataFrame(discriminator.predict(X_test))\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14014, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.999798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.904467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.999798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.999891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.999941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  14014.000000\n",
       "mean       0.999798\n",
       "std        0.001221\n",
       "min        0.904467\n",
       "25%        0.999798\n",
       "50%        0.999891\n",
       "75%        0.999941\n",
       "max        0.999996"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pred_df.shape)\n",
    "pred_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14014, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_df = pd.DataFrame(scaler.fit_transform(pred_df))\n",
    "scaled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.997932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.997926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.998905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.999432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  14014.000000\n",
       "mean       0.997932\n",
       "std        0.012781\n",
       "min        0.000000\n",
       "25%        0.997926\n",
       "50%        0.998905\n",
       "75%        0.999432\n",
       "max        1.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
